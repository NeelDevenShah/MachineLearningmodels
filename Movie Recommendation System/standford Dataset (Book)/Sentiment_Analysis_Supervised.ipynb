{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66a5d781-0a24-440f-8010-b57593c0ca11",
   "metadata": {},
   "source": [
    "Importing necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e107cd7-5062-4bec-bb1d-878cd983eeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 19:10:18.662082: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-22 19:10:18.952194: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-22 19:10:19.002224: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-22 19:10:19.002242: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-22 19:10:19.804092: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-22 19:10:19.804145: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-22 19:10:19.804150: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import text_normalizer as tn\n",
    "import model_evaluation_utils as meu\n",
    "\n",
    "np.set_printoptions(precision=2, linewidth=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1d38f7-6a96-4950-8abe-e54b32acc462",
   "metadata": {},
   "source": [
    "Load and normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d8f1153-bc77-4a9f-9891-206ddd0cfbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neel/anaconda3/lib/python3.9/site-packages/bs4/__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(r'movie_reviews.csv')\n",
    "\n",
    "# Take a peek at the data\n",
    "print(dataset.head())\n",
    "reviews = np.array(dataset['review'])\n",
    "sentiments = np.array(dataset['sentiment'])\n",
    "\n",
    "# Build train and test dataset\\\n",
    "train_reviews = reviews[:35000]\n",
    "train_sentiments = sentiments[:35000]\n",
    "test_reviews = reviews[35000:]\n",
    "test_sentiments = sentiments[35000:]\n",
    "\n",
    "# Normalize Datasets\n",
    "norm_train_reviews = tn.normalize_corpus(train_reviews)\n",
    "norm_test_reviews = tn.normalize_corpus(test_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2594636-19f6-4b68-b153-d3ccca2ad773",
   "metadata": {},
   "source": [
    "<b><b>Traditional Supervised Machine Learning Models</b></b>\n",
    "</br>Feature Enginerring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7e36adf-ef98-4bae-9aea-4eaf2d94c90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Build BOW features on train reviews\n",
    "cv = CountVectorizer(binary=False, min_df=0.0, max_df=1.0, ngram_range=(1,2))\n",
    "cv_train_features = cv.fit_transform(norm_train_reviews)\n",
    "# Build TFIDF features on train reviews\n",
    "tv = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0, ngram_range=(1,2), sublinear_tf=True)\n",
    "tv_train_features = tv.fit_transform(norm_train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bf18396-5648-4042-8c9e-0c346fe9e39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform test reviews into features\n",
    "cv_test_features = cv.transform(norm_test_reviews)\n",
    "tv_test_features = tv.transform(norm_test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ea377d3-162e-4dc4-b1b5-a2ad057fa353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW model:> Train features shape: (35000, 2109595) Test features shape: (15000, 2109595)\n",
      "TFIDF model:> Train features shape: (35000, 2109595) Test features shape: (15000, 2109595)\n"
     ]
    }
   ],
   "source": [
    "print('BOW model:> Train features shape:', cv_train_features.shape, 'Test features shape:', cv_test_features.shape)\n",
    "print('TFIDF model:> Train features shape:', tv_train_features.shape, 'Test features shape:', tv_test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2812bc65-adb5-40d5-a00e-cba50ce41f3f",
   "metadata": {},
   "source": [
    "<b>Model Training, Prediction and Performance Evaluation</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d39fec3d-8de4-4837-9507-6c815e70667b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', max_iter=100, C=1)\n",
    "svm = SGDClassifier(loss='hinge', n_iter_no_change=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22da0795-6499-4e83-bff1-bade1451d9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neel/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.9064\n",
      "Precision: 0.9064\n",
      "Recall: 0.9064\n",
      "F1 Score: 0.9064\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.90      0.91      0.91      7510\n",
      "    negative       0.91      0.90      0.91      7490\n",
      "\n",
      "    accuracy                           0.91     15000\n",
      "   macro avg       0.91      0.91      0.91     15000\n",
      "weighted avg       0.91      0.91      0.91     15000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__new__() got an unexpected keyword argument 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2865/1567078223.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Losgistic Regression model on BOW features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlr_bow_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_predict_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv_train_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_sentiments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_test_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_sentiments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmeu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_model_performance_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_sentiments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr_bow_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'positive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'negative'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/neel/Projects/MachineLearningmodels/Movie Recommendation System/standford Dataset (Book)/model_evaluation_utils.py\u001b[0m in \u001b[0;36mdisplay_model_performance_metrics\u001b[0;34m(true_labels, predicted_labels, classes)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nPrediction Confusion Matrix:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     display_confusion_matrix(true_labels=true_labels, predicted_labels=predicted_labels, \n\u001b[0m\u001b[1;32m     87\u001b[0m                              classes=classes)\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/neel/Projects/MachineLearningmodels/Movie Recommendation System/standford Dataset (Book)/model_evaluation_utils.py\u001b[0m in \u001b[0;36mdisplay_confusion_matrix\u001b[0;34m(true_labels, predicted_labels, classes)\u001b[0m\n\u001b[1;32m     59\u001b[0m                                   labels=classes)\n\u001b[1;32m     60\u001b[0m     cm_frame = pd.DataFrame(data=cm, \n\u001b[0;32m---> 61\u001b[0;31m                             columns=pd.MultiIndex(levels=[['Predicted:'], classes], \n\u001b[0m\u001b[1;32m     62\u001b[0m                                                   labels=level_labels), \n\u001b[1;32m     63\u001b[0m                             index=pd.MultiIndex(levels=[['Actual:'], classes], \n",
      "\u001b[0;31mTypeError\u001b[0m: __new__() got an unexpected keyword argument 'labels'"
     ]
    }
   ],
   "source": [
    "# Losgistic Regression model on BOW features\n",
    "lr_bow_predictions = meu.train_predict_model(classifier=lr, train_features=cv_train_features, train_labels=train_sentiments, test_features = cv_test_features, test_labels=test_sentiments)\n",
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=lr_bow_predictions, classes=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "940fbe02-2a0c-4871-9a6e-5211283dd6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.8939\n",
      "Precision: 0.8939\n",
      "Recall: 0.8939\n",
      "F1 Score: 0.8939\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.89      0.90      0.89      7510\n",
      "    negative       0.90      0.89      0.89      7490\n",
      "\n",
      "    accuracy                           0.89     15000\n",
      "   macro avg       0.89      0.89      0.89     15000\n",
      "weighted avg       0.89      0.89      0.89     15000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__new__() got an unexpected keyword argument 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2865/2404781103.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Logistic Regression model on TF-IDF features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlr_tfidf_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_predict_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtv_train_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_sentiments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtv_test_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_sentiments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmeu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_model_performance_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_sentiments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr_tfidf_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'positive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'negative'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/neel/Projects/MachineLearningmodels/Movie Recommendation System/standford Dataset (Book)/model_evaluation_utils.py\u001b[0m in \u001b[0;36mdisplay_model_performance_metrics\u001b[0;34m(true_labels, predicted_labels, classes)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nPrediction Confusion Matrix:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     display_confusion_matrix(true_labels=true_labels, predicted_labels=predicted_labels, \n\u001b[0m\u001b[1;32m     87\u001b[0m                              classes=classes)\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/neel/Projects/MachineLearningmodels/Movie Recommendation System/standford Dataset (Book)/model_evaluation_utils.py\u001b[0m in \u001b[0;36mdisplay_confusion_matrix\u001b[0;34m(true_labels, predicted_labels, classes)\u001b[0m\n\u001b[1;32m     59\u001b[0m                                   codes=classes)\n\u001b[1;32m     60\u001b[0m     cm_frame = pd.DataFrame(data=cm, \n\u001b[0;32m---> 61\u001b[0;31m                             columns=pd.MultiIndex(levels=[['Predicted:'], classes], \n\u001b[0m\u001b[1;32m     62\u001b[0m                                                   codes=level_labels), \n\u001b[1;32m     63\u001b[0m                             index=pd.MultiIndex(levels=[['Actual:'], classes], \n",
      "\u001b[0;31mTypeError\u001b[0m: __new__() got an unexpected keyword argument 'labels'"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model on TF-IDF features\n",
    "lr_tfidf_predictions = meu.train_predict_model(classifier=lr, train_features=tv_train_features, train_labels=train_sentiments, test_features = tv_test_features, test_labels=test_sentiments)\n",
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=lr_tfidf_predictions, classes=['positive', 'negative'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e2a2f76-7f80-4e80-a08b-088c08ab7504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.8979\n",
      "Precision: 0.8984\n",
      "Recall: 0.8979\n",
      "F1 Score: 0.8979\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.91      0.88      0.90      7510\n",
      "    negative       0.88      0.92      0.90      7490\n",
      "\n",
      "    accuracy                           0.90     15000\n",
      "   macro avg       0.90      0.90      0.90     15000\n",
      "weighted avg       0.90      0.90      0.90     15000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__new__() got an unexpected keyword argument 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2865/1065972433.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msvm_bow_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_predict_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv_train_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_sentiments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv_test_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_sentiments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmeu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_model_performance_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_sentiments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvm_bow_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'positive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'negative'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/neel/Projects/MachineLearningmodels/Movie Recommendation System/standford Dataset (Book)/model_evaluation_utils.py\u001b[0m in \u001b[0;36mdisplay_model_performance_metrics\u001b[0;34m(true_labels, predicted_labels, classes)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nPrediction Confusion Matrix:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     display_confusion_matrix(true_labels=true_labels, predicted_labels=predicted_labels, \n\u001b[0m\u001b[1;32m     87\u001b[0m                              classes=classes)\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/neel/Projects/MachineLearningmodels/Movie Recommendation System/standford Dataset (Book)/model_evaluation_utils.py\u001b[0m in \u001b[0;36mdisplay_confusion_matrix\u001b[0;34m(true_labels, predicted_labels, classes)\u001b[0m\n\u001b[1;32m     59\u001b[0m                                   codes=classes)\n\u001b[1;32m     60\u001b[0m     cm_frame = pd.DataFrame(data=cm, \n\u001b[0;32m---> 61\u001b[0;31m                             columns=pd.MultiIndex(levels=[['Predicted:'], classes], \n\u001b[0m\u001b[1;32m     62\u001b[0m                                                   codes=level_labels), \n\u001b[1;32m     63\u001b[0m                             index=pd.MultiIndex(levels=[['Actual:'], classes], \n",
      "\u001b[0;31mTypeError\u001b[0m: __new__() got an unexpected keyword argument 'labels'"
     ]
    }
   ],
   "source": [
    "svm_bow_predictions = meu.train_predict_model(classifier=svm, train_features=cv_train_features, train_labels=train_sentiments, test_features=cv_test_features, test_labels=test_sentiments)\n",
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=svm_bow_predictions, classes=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1972c5be-2162-40ac-9f86-2907c792d1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.8959\n",
      "Precision: 0.8962\n",
      "Recall: 0.8959\n",
      "F1 Score: 0.8958\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.88      0.91      0.90      7510\n",
      "    negative       0.91      0.88      0.89      7490\n",
      "\n",
      "    accuracy                           0.90     15000\n",
      "   macro avg       0.90      0.90      0.90     15000\n",
      "weighted avg       0.90      0.90      0.90     15000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__new__() got an unexpected keyword argument 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2865/281866153.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msvm_tfidf_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_predict_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtv_train_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_sentiments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtv_test_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_sentiments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmeu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_model_performance_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_sentiments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvm_tfidf_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'positive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'negative'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/neel/Projects/MachineLearningmodels/Movie Recommendation System/standford Dataset (Book)/model_evaluation_utils.py\u001b[0m in \u001b[0;36mdisplay_model_performance_metrics\u001b[0;34m(true_labels, predicted_labels, classes)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nPrediction Confusion Matrix:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     display_confusion_matrix(true_labels=true_labels, predicted_labels=predicted_labels, \n\u001b[0m\u001b[1;32m     87\u001b[0m                              classes=classes)\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/neel/Projects/MachineLearningmodels/Movie Recommendation System/standford Dataset (Book)/model_evaluation_utils.py\u001b[0m in \u001b[0;36mdisplay_confusion_matrix\u001b[0;34m(true_labels, predicted_labels, classes)\u001b[0m\n\u001b[1;32m     59\u001b[0m                                   codes=classes)\n\u001b[1;32m     60\u001b[0m     cm_frame = pd.DataFrame(data=cm, \n\u001b[0;32m---> 61\u001b[0;31m                             columns=pd.MultiIndex(levels=[['Predicted:'], classes], \n\u001b[0m\u001b[1;32m     62\u001b[0m                                                   codes=level_labels), \n\u001b[1;32m     63\u001b[0m                             index=pd.MultiIndex(levels=[['Actual:'], classes], \n",
      "\u001b[0;31mTypeError\u001b[0m: __new__() got an unexpected keyword argument 'labels'"
     ]
    }
   ],
   "source": [
    "svm_tfidf_predictions = meu.train_predict_model(classifier=svm, train_features=tv_train_features, train_labels=train_sentiments, test_features=tv_test_features, test_labels=test_sentiments)\n",
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=svm_tfidf_predictions, classes=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5d2c39-5c8c-4fd3-bc30-6694d2195c68",
   "metadata": {},
   "source": [
    "<b>Newer Supurvised Deep Learning Models</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cc77096-1f2c-45b6-9f9b-3fae0a181323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Activation, Dense\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed10401a-929f-497b-af36-0a7c5b5ca16c",
   "metadata": {},
   "source": [
    "Prediction class label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dc14f1b-5ec9-4de9-952a-8e03bb0023a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "num_classes =2\n",
    "# Tokenize train reviews & encode train labels\n",
    "tokenized_train = [tn.tokenizer.tokenize(text) for text in norm_train_reviews]\n",
    "y_tr = le.fit_transform(train_sentiments)\n",
    "y_train = keras.utils.to_categorical(y_tr, num_classes)\n",
    "# tokenize text reviews & encode test labels\n",
    "tokenized_test = [tn.tokenizer.tokenize(text) for text in norm_test_reviews]\n",
    "y_ts = le.fit_transform(test_sentiments)\n",
    "y_test = keras.utils.to_categorical(y_ts, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eceb6ca9-24de-44ef-9907-3d272eda01d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment class label map: {'negative': 0, 'positive': 1}\n",
      "Sample test labels transformation:\n",
      "----------------------------------- \n",
      "Actual Labels: ['negative' 'positive' 'negative'] \n",
      "Encoded Labels: [0 1 0] \n",
      "One hot encoded Labels:\n",
      " [[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# print class labels encoding map and encoded labels\n",
    "print('Sentiment class label map:', dict(zip(le.classes_, le.transform(le.classes_))))\n",
    "print('Sample test labels transformation:\\n'+'-'*35, '\\nActual Labels:', test_sentiments[:3], '\\nEncoded Labels:', y_ts[:3], '\\nOne hot encoded Labels:\\n', y_test[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c1bdf0-c454-4cc1-b35b-bac7f4ff6a59",
   "metadata": {},
   "source": [
    "<b>Feature Engineering with word embeddings</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c65f84c0-0d74-4438-aabe-2c8d0c107e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build word2vec model\n",
    "w2v_num_features = 500\n",
    "w2v_model = gensim.models.Word2Vec(tokenized_train, vector_size=w2v_num_features, window=150, min_count=10, sample=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1ed106a-8a21-4efc-b693-6e6f963078ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def averaged_word2vec_vectorizer(corpus, model, num_features):\n",
    "    vocabulary = set(model.wv.index_to_key)\n",
    "    \n",
    "    def average_word_vectors(words, model, vocabulary, num_features):\n",
    "        feature_vector = np.zeros((num_features,), dtype=\"float64\")\n",
    "        nwords = 0\n",
    "        \n",
    "        for word in words:\n",
    "            if word in vocabulary: \n",
    "                nwords = nwords + 1\n",
    "                feature_vector = np.add(feature_vector, model.wv[word])\n",
    "        if nwords:\n",
    "            feature_vector = np.divide(feature_vector, nwords)\n",
    "\n",
    "        return feature_vector\n",
    "\n",
    "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features) for tokenized_sentence in corpus]\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "452aa31c-4ea8-4d81-b4a5-46374fabbfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate averaged word vector features from word2vec model\n",
    "avg_wv_train_features = averaged_word2vec_vectorizer(corpus=tokenized_train, model=w2v_model, num_features=500)\n",
    "avg_wv_test_features = averaged_word2vec_vectorizer(corpus=tokenized_test, model=w2v_model, num_features=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd33e8c4-972f-45f0-806e-4774e0a6c19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5   0.75  0.5  ...  0.27  0.32  0.28]\n",
      " [ 0.3   0.26  0.05 ... -0.49 -0.3  -0.31]\n",
      " [ 0.13  0.22  0.24 ...  0.09  0.14 -0.34]\n",
      " ...\n",
      " [-0.13 -0.08 -0.22 ... -0.8  -0.32 -0.45]\n",
      " [ 0.38  0.45 -0.09 ... -0.09  0.1   0.21]\n",
      " [-0.2   0.34  0.42 ...  0.1  -0.11 -0.6 ]]\n",
      "-----------------------\n",
      "[[ 0.35  0.53  0.19 ... -0.13  0.17 -0.47]\n",
      " [ 0.4   0.05  0.21 ...  0.14  0.27 -0.31]\n",
      " [ 0.65  0.44  0.18 ... -0.34  0.18 -0.34]\n",
      " ...\n",
      " [ 0.31  0.7   0.65 ... -0.    0.24  0.04]\n",
      " [ 0.45  0.26  0.05 ... -0.08  0.07 -0.11]\n",
      " [-0.21  0.43  0.57 ...  0.23 -0.1  -0.52]]\n"
     ]
    }
   ],
   "source": [
    "print(avg_wv_train_features)\n",
    "print('-----------------------')\n",
    "print(avg_wv_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1391daf1-ebfc-4deb-a382-ca0bf7639d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature enginerring with GloVe model\n",
    "train_nlp = [tn.nlp(item) for item in norm_train_reviews]\n",
    "train_glove_features = np.array([item.vector for item in train_nlp])\n",
    "\n",
    "test_nlp = [tn.nlp(item) for item in norm_test_reviews]\n",
    "test_glove_features = np.array([item.vector for item in test_nlp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ec98aeb7-b4da-48fe-a607-6edba3816ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec model:> Train features shape: (35000, 500)  Test features shape: (15000, 500)\n",
      "GloVe model:> Train features shape: (35000, 96)  Test features shape: (15000, 96)\n"
     ]
    }
   ],
   "source": [
    "print('Word2Vec model:> Train features shape:', avg_wv_train_features.shape, ' Test features shape:', avg_wv_test_features.shape)\n",
    "print('GloVe model:> Train features shape:', train_glove_features.shape, ' Test features shape:', test_glove_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f94529c-5881-4031-a120-a3f0f4090aa0",
   "metadata": {},
   "source": [
    "<b>Model with deep neural networks</b>\n",
    "</br>Building Deep neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c70c003-3154-4eff-8857-9b2dfed7f5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_deepnn_architecture(num_input_features):\n",
    "    dnn_model = Sequential()\n",
    "    dnn_model.add(Dense(512, activation='relu', input_shape=(num_input_features,)))\n",
    "    dnn_model.add(Dropout(0.2))\n",
    "    dnn_model.add(Dense(512, activation='relu'))\n",
    "    dnn_model.add(Dropout(0.2))\n",
    "    dnn_model.add(Dense(512, activation='relu'))\n",
    "    dnn_model.add(Dropout(0.2))\n",
    "    dnn_model.add(Dense(2))\n",
    "    dnn_model.add(Activation('softmax'))\n",
    "    \n",
    "    dnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return dnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "502ded17-2607-4b4b-af5d-0c0a4b6be5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 19:35:45.066075: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-12-22 19:35:45.066378: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-22 19:35:45.066411: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (pop-os): /proc/driver/nvidia/version does not exist\n",
      "2022-12-22 19:35:45.067107: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "w2v_dnn = construct_deepnn_architecture(num_input_features=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8a6932-e5f3-4b76-8e07-7b677412cbe7",
   "metadata": {},
   "source": [
    "<b>Visualize sample deep acrhitecture</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4803870-249b-4b2c-86eb-8da9c4d13ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"376pt\" height=\"959pt\" viewBox=\"0.00 0.00 282.00 719.00\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1.33 1.33) rotate(0) translate(4 715)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-715 278,-715 278,4 -4,4\"/>\n",
       "<!-- 139879079822288 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>139879079822288</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-664.5 0,-710.5 274,-710.5 274,-664.5 0,-664.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"47.5\" y=\"-683.8\" font-family=\"Times,serif\" font-size=\"14.00\">InputLayer</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"95,-664.5 95,-710.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"129\" y=\"-695.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"95,-687.5 163,-687.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"129\" y=\"-672.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"163,-664.5 163,-710.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"218.5\" y=\"-695.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 500)]</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"163,-687.5 274,-687.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"218.5\" y=\"-672.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 500)]</text>\n",
       "</g>\n",
       "<!-- 139879482126192 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>139879482126192</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"22,-581.5 22,-627.5 252,-627.5 252,-581.5 22,-581.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"52.5\" y=\"-600.8\" font-family=\"Times,serif\" font-size=\"14.00\">Dense</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"83,-581.5 83,-627.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"117\" y=\"-612.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"83,-604.5 151,-604.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"117\" y=\"-589.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"151,-581.5 151,-627.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"201.5\" y=\"-612.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 500)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"151,-604.5 252,-604.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"201.5\" y=\"-589.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 139879079822288&#45;&gt;139879482126192 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>139879079822288-&gt;139879482126192</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M137,-664.37C137,-656.15 137,-646.66 137,-637.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"140.5,-637.61 137,-627.61 133.5,-637.61 140.5,-637.61\"/>\n",
       "</g>\n",
       "<!-- 139879493904320 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>139879493904320</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"15,-498.5 15,-544.5 259,-544.5 259,-498.5 15,-498.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"52.5\" y=\"-517.8\" font-family=\"Times,serif\" font-size=\"14.00\">Dropout</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"90,-498.5 90,-544.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"124\" y=\"-529.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"90,-521.5 158,-521.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"124\" y=\"-506.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"158,-498.5 158,-544.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"208.5\" y=\"-529.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"158,-521.5 259,-521.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"208.5\" y=\"-506.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 139879482126192&#45;&gt;139879493904320 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>139879482126192-&gt;139879493904320</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M137,-581.37C137,-573.15 137,-563.66 137,-554.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"140.5,-554.61 137,-544.61 133.5,-554.61 140.5,-554.61\"/>\n",
       "</g>\n",
       "<!-- 139879490171520 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>139879490171520</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"22,-415.5 22,-461.5 252,-461.5 252,-415.5 22,-415.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"52.5\" y=\"-434.8\" font-family=\"Times,serif\" font-size=\"14.00\">Dense</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"83,-415.5 83,-461.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"117\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"83,-438.5 151,-438.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"117\" y=\"-423.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"151,-415.5 151,-461.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"201.5\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"151,-438.5 252,-438.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"201.5\" y=\"-423.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 139879493904320&#45;&gt;139879490171520 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>139879493904320-&gt;139879490171520</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M137,-498.37C137,-490.15 137,-480.66 137,-471.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"140.5,-471.61 137,-461.61 133.5,-471.61 140.5,-471.61\"/>\n",
       "</g>\n",
       "<!-- 139879490637536 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>139879490637536</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"15,-332.5 15,-378.5 259,-378.5 259,-332.5 15,-332.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"52.5\" y=\"-351.8\" font-family=\"Times,serif\" font-size=\"14.00\">Dropout</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"90,-332.5 90,-378.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"124\" y=\"-363.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"90,-355.5 158,-355.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"124\" y=\"-340.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"158,-332.5 158,-378.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"208.5\" y=\"-363.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"158,-355.5 259,-355.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"208.5\" y=\"-340.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 139879490171520&#45;&gt;139879490637536 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>139879490171520-&gt;139879490637536</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M137,-415.37C137,-407.15 137,-397.66 137,-388.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"140.5,-388.61 137,-378.61 133.5,-388.61 140.5,-388.61\"/>\n",
       "</g>\n",
       "<!-- 139879482051600 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>139879482051600</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"22,-249.5 22,-295.5 252,-295.5 252,-249.5 22,-249.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"52.5\" y=\"-268.8\" font-family=\"Times,serif\" font-size=\"14.00\">Dense</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"83,-249.5 83,-295.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"117\" y=\"-280.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"83,-272.5 151,-272.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"117\" y=\"-257.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"151,-249.5 151,-295.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"201.5\" y=\"-280.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"151,-272.5 252,-272.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"201.5\" y=\"-257.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 139879490637536&#45;&gt;139879482051600 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>139879490637536-&gt;139879482051600</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M137,-332.37C137,-324.15 137,-314.66 137,-305.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"140.5,-305.61 137,-295.61 133.5,-305.61 140.5,-305.61\"/>\n",
       "</g>\n",
       "<!-- 139879504555744 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>139879504555744</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"15,-166.5 15,-212.5 259,-212.5 259,-166.5 15,-166.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"52.5\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\">Dropout</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"90,-166.5 90,-212.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"124\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"90,-189.5 158,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"124\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"158,-166.5 158,-212.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"208.5\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"158,-189.5 259,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"208.5\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 139879482051600&#45;&gt;139879504555744 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>139879482051600-&gt;139879504555744</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M137,-249.37C137,-241.15 137,-231.66 137,-222.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"140.5,-222.61 137,-212.61 133.5,-222.61 140.5,-222.61\"/>\n",
       "</g>\n",
       "<!-- 139878968528608 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>139878968528608</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"22,-83.5 22,-129.5 252,-129.5 252,-83.5 22,-83.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"52.5\" y=\"-102.8\" font-family=\"Times,serif\" font-size=\"14.00\">Dense</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"83,-83.5 83,-129.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"117\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"83,-106.5 151,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"117\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"151,-83.5 151,-129.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"201.5\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"151,-106.5 252,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"201.5\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 2)</text>\n",
       "</g>\n",
       "<!-- 139879504555744&#45;&gt;139878968528608 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>139879504555744-&gt;139878968528608</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M137,-166.37C137,-158.15 137,-148.66 137,-139.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"140.5,-139.61 137,-129.61 133.5,-139.61 140.5,-139.61\"/>\n",
       "</g>\n",
       "<!-- 139878968533200 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>139878968533200</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"17,-0.5 17,-46.5 257,-46.5 257,-0.5 17,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"61.5\" y=\"-19.8\" font-family=\"Times,serif\" font-size=\"14.00\">Activation</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"106,-0.5 106,-46.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"140\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"106,-23.5 174,-23.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"140\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"174,-0.5 174,-46.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"215.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 2)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"174,-23.5 257,-23.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"215.5\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 2)</text>\n",
       "</g>\n",
       "<!-- 139878968528608&#45;&gt;139878968533200 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>139878968528608-&gt;139878968533200</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M137,-83.37C137,-75.15 137,-65.66 137,-56.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"140.5,-56.61 137,-46.61 133.5,-56.61 140.5,-56.61\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "# SVG stands for Scalable Vector Graphics. SVG defines vector-based graphics in XML format.\n",
    "SVG(model_to_dot(w2v_dnn, show_shapes=True, show_layer_names=False, rankdir='TB').create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb64632-a72a-414f-ab16-92eccd16cd2e",
   "metadata": {},
   "source": [
    "<b>Model Training, Prediction and Performance Evaluation</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57a1fddf-a480-4a7f-a847-198330a12504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "315/315 [==============================] - 3s 7ms/step - loss: 0.3081 - accuracy: 0.8717 - val_loss: 0.3002 - val_accuracy: 0.8740\n",
      "Epoch 2/5\n",
      "315/315 [==============================] - 2s 6ms/step - loss: 0.2826 - accuracy: 0.8855 - val_loss: 0.2939 - val_accuracy: 0.8780\n",
      "Epoch 3/5\n",
      "315/315 [==============================] - 2s 7ms/step - loss: 0.2772 - accuracy: 0.8868 - val_loss: 0.2918 - val_accuracy: 0.8754\n",
      "Epoch 4/5\n",
      "315/315 [==============================] - 2s 7ms/step - loss: 0.2668 - accuracy: 0.8897 - val_loss: 0.2916 - val_accuracy: 0.8780\n",
      "Epoch 5/5\n",
      "315/315 [==============================] - 2s 7ms/step - loss: 0.2611 - accuracy: 0.8928 - val_loss: 0.2962 - val_accuracy: 0.8766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f381c44cfd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "w2v_dnn.fit(avg_wv_train_features, y_train, epochs=5, batch_size=batch_size, shuffle=True, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "adde446e-1236-4360-ae9a-e317cf67d838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = w2v_dnn.predict(avg_wv_test_features)\n",
    "prediction=[]\n",
    "for n in y_pred:\n",
    "    if n[1]>n[0]:\n",
    "        prediction.append('positive')\n",
    "    else:\n",
    "        prediction.append('negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87dfd4a7-7cf1-45de-8462-d177844dad1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative' 'positive' 'negative' ... 'negative' 'negative' 'negative']\n"
     ]
    }
   ],
   "source": [
    "print(test_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b9561c11-327d-4965-a2a9-afa12bf24354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.8828\n",
      "Precision: 0.8836\n",
      "Recall: 0.8828\n",
      "F1 Score: 0.8827\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "classification_report() got an unexpected keyword argument 'codes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2880/2946272861.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmeu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_model_performance_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_sentiments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'positive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'negative'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/neel/Projects/MachineLearningmodels/Movie Recommendation System/standford Dataset (Book)/model_evaluation_utils.py\u001b[0m in \u001b[0;36mdisplay_model_performance_metrics\u001b[0;34m(true_labels, predicted_labels, classes)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nModel Classification report:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     display_classification_report(true_labels=true_labels, predicted_labels=predicted_labels, \n\u001b[0m\u001b[1;32m     83\u001b[0m                                   classes=classes)\n\u001b[1;32m     84\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nPrediction Confusion Matrix:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/neel/Projects/MachineLearningmodels/Movie Recommendation System/standford Dataset (Book)/model_evaluation_utils.py\u001b[0m in \u001b[0;36mdisplay_classification_report\u001b[0;34m(true_labels, predicted_labels, classes)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdisplay_classification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     report = metrics.classification_report(y_true=true_labels, \n\u001b[0m\u001b[1;32m     70\u001b[0m                                            \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredicted_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                                            codes=classes) \n",
      "\u001b[0;31mTypeError\u001b[0m: classification_report() got an unexpected keyword argument 'codes'"
     ]
    }
   ],
   "source": [
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=prediction, classes=['positive', 'negative'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1b6bafae-5251-4aab-8e02-01ee7e3e8691",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_dnn = construct_deepnn_architecture(num_input_features=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3f3fc4bf-65da-4c2b-a837-f6c74a22c163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/neel/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/neel/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/neel/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/neel/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/neel/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/neel/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 300), found shape=(100, 96)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2880/4173415310.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mglove_dnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_glove_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/neel/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/neel/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/neel/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/neel/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/neel/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/neel/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 300), found shape=(100, 96)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "glove_dnn.fit(train_glove_features, y_train, epochs=5, batch_size=batch_size, shuffle=True, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f758c6d-5e55-4acb-912d-f4d7ca7eac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = glove_dnn.predict_classes(test_glove_features)\n",
    "predictions = le.inverse_transform(y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aa8fc9-66ae-4584-abef-efba16e058e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=predictions, classes=['positive', 'negative']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec46ec7d-b525-4522-9506-cee480a5c171",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
